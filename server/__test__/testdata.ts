import {Request, Response} from "express";
import fs from 'fs';
//import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import os from 'os';
import {config} from 'dotenv';

import * as controller from '../listening-quiz-transactions/lquizcontrollers.ts';
import * as apierror from '../listening-quiz-transactions/errors/lquiz.apierrors.ts';
import * as schema from '../listening-quiz-transactions/schemas/lquizapischema.ts';
import {JPN_AUDIO_SCRIPT_FORMAT} from '../listening-quiz-transactions/services/services.types.ts';
import * as apiservice from '../listening-quiz-transactions/services/lquizapiservice.ts';


import * as dto from '../listening-quiz-transactions/lquiz.dto.ts';
import z from 'zod';
import session from 'express-session';
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

config({path: path.join(__dirname, '../.env')});
const projectRoot = path.resolve(__dirname, '../');  // serverãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
const credentialsPath = path.join(projectRoot, 'credentials/listening-quiz-audio-generator-b5d3be486e8f.json');

process.env.GOOGLE_APPLICATION_CREDENTIALS = credentialsPath;


export async function callChatGPTForPart2AudioScript(prompt: string): Promise<{audioScript: string, answerOption: string}> {
    try {
        console.log('=== Step 1: fetché–‹å§‹ (AudioScriptç”Ÿæˆ) ===');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: "You are an expert in TOEIC content creation. Return ONLY a valid JSON object with audioScript and answerOption fields as specified in the prompt. Do not include markdown code blocks or any other formatting."
                    },
                    {
                        role: "user",
                        content: prompt
                    }
                ],
                temperature: 0.3,  // ä¸€è²«æ€§é‡è¦–ã€é©åº¦ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
                max_tokens: 500,   // å¿…è¦ååˆ†ãªé•·ã•
                top_p: 0.9        // è¿½åŠ : ã‚ˆã‚Šå®‰å®šã—ãŸå‡ºåŠ›
            }),
            signal: AbortSignal.timeout(60000)
        });
        
        console.log("response status:", response.status);
        console.log('=== Step 2: responseç¢ºèª ===');
        
        if (!response.ok) {
            throw new apierror.ChatGPTAPIError(`ChatGPT API Error: ${response.status} ${response.statusText}`);
        }
        
        console.log('=== Step 3: JSON parseé–‹å§‹ ===');
        const data = await response.json();
        
        console.log('=== Step 4: OpenAI APIã®å¿œç­”æ§‹é€ æ¤œè¨¼ ===');
        const validatedData = schema.openAIResponseSchema.parse(data);

        if (validatedData.choices.length === 0) {
            throw new apierror.ChatGPTAPIError('ChatGPT APIã‹ã‚‰ã®å¿œç­”ã«å•é¡ŒãŒã‚ã‚Šã¾ã™');
        }

        console.log('=== Step 5: audioScript&answerOptionæŠ½å‡º ===');
        const jsonResponse = validatedData.choices[0].message.content;

        // ä¸è¦ãªæ–‡å­—åˆ—ã®é™¤å»ï¼ˆmarkdownå½¢å¼ç­‰ï¼‰
        let cleanedResponse = jsonResponse.trim();
        cleanedResponse = cleanedResponse.replace(/^```json\s*/, ''); // å…ˆé ­ã®```jsonã‚’å‰Šé™¤
        cleanedResponse = cleanedResponse.replace(/^```.*\n?/, '');   // å…ˆé ­ã®```ã‚’å‰Šé™¤
        cleanedResponse = cleanedResponse.replace(/\n?```$/, '');     // æœ«å°¾ã®```ã‚’å‰Šé™¤

        console.log('=== Step 6: JSON parseå®Ÿè¡Œ ===');
        const parsedJson = JSON.parse(cleanedResponse);

        //ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã®æ¤œè¨¼
        if (!parsedJson.audioScript || !parsedJson.answerOption) {
            throw new apierror.ChatGPTAPIError('å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆaudioScript, answerOptionï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™');
        }
        
        console.log('=== Step 7: æ¤œè¨¼å®Œäº† ===');
        console.log("audioScript length:", parsedJson.audioScript.length);
        console.log("answerOption:", parsedJson.answerOption);

        return {
            audioScript: parsedJson.audioScript,
            answerOption: parsedJson.answerOption
        }
        
    } catch (error) {
        if (error instanceof z.ZodError) {
            console.error(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ:`, error);
            throw new apierror.ChatGPTAPIError(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ: ${error.message}`);
        } else if (error instanceof apierror.ChatGPTAPIError) {
            throw error;
        } else {
            console.error('Unexpected ChatGPT API Error:', error);
            throw new apierror.ChatGPTAPIError('ChatGPT APIã¨ã®é€šä¿¡ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
        }
    }
};
//chatgpt - audioScript generation only
export async function callChatGPTForAudioScriptContent(prompt: string): Promise<string> {
    try {
        console.log('=== Step 1: fetché–‹å§‹ (AudioScriptç”Ÿæˆ) ===');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: "You are an expert in TOEIC content creation. Return ONLY the audioScript content as plain text with proper speaker tags. Do not include JSON formatting, markdown code blocks, or any other formatting. Output only the conversation/speech content exactly as specified in the prompt."
                    },
                    {
                        role: "user",
                        content: prompt
                    }
                ],
                temperature: 0,
                max_tokens: 1000
            }),
            signal: AbortSignal.timeout(60000)
        });
        
        console.log("response status:", response.status);
        console.log('=== Step 2: responseç¢ºèª ===');
        
        if (!response.ok) {
            throw new apierror.ChatGPTAPIError(`ChatGPT API Error: ${response.status} ${response.statusText}`);
        }
        
        console.log('=== Step 3: JSON parseé–‹å§‹ ===');
        const data = await response.json();
        
        console.log('=== Step 4: OpenAI APIã®å¿œç­”æ§‹é€ æ¤œè¨¼ ===');
        const validatedData = schema.openAIResponseSchema.parse(data);

        if (validatedData.choices.length === 0) {
            throw new apierror.ChatGPTAPIError('ChatGPT APIã‹ã‚‰ã®å¿œç­”ã«å•é¡ŒãŒã‚ã‚Šã¾ã™');
        }

        console.log('=== Step 5: audioScriptæŠ½å‡º ===');
        const audioScriptContent = validatedData.choices[0].message.content;

        //å‰å¾Œã®ç©ºç™½é™¤å»
        const cleanedAudioScript = audioScriptContent.trim();
        
        console.log("cleaned audioScript: ", cleanedAudioScript);
        console.log('=== Step 6: audioScriptæ¤œè¨¼å®Œäº† ===');
        console.log("generated audioScript length:", cleanedAudioScript.length);

        //JSONãƒ‘ãƒ¼ã‚¹ã‚’å‰Šé™¤ã—ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
        return cleanedAudioScript;
        
    } catch (error) {
        if (error instanceof z.ZodError) {
            console.error(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ:`, error);
            throw new apierror.ChatGPTAPIError(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ: ${error.message}`);
        } else if (error instanceof apierror.ChatGPTAPIError) {
            throw error;
        } else {
            console.error('Unexpected ChatGPT API Error:', error);
            throw new apierror.ChatGPTAPIError('ChatGPT APIã¨ã®é€šä¿¡ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
        }
    }
};

export async function callChatGPTForAudioScriptQuestions(prompt: string): Promise<{audioScript: string, answerOptionList: string[]}> {
    try {
        console.log('=== Step 1: fetché–‹å§‹ (Questions&Choicesç”Ÿæˆ) ===');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: "You are an expert in TOEIC question creation. Return ONLY a valid JSON object with audioScript and answerOption fields. Do not use markdown code blocks or any other formatting. Output only the JSON object exactly as specified in the prompt."
                    },
                    {
                        role: "user",
                        content: prompt
                    }
                ],
                temperature: 0.4,        // å¤‰æ›´: 0 â†’ 0.4 (å‰µé€ æ€§ã¨ä¸€è²«æ€§ã®ãƒãƒ©ãƒ³ã‚¹)
                max_tokens: 3000,       // å¤‰æ›´: 2000 â†’ 3000 (æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ç”¨)
                top_p: 0.9,             // è¿½åŠ : ã‚ˆã‚Šè³ªã®é«˜ã„é¸æŠ
                presence_penalty: 0.1,   // è¿½åŠ : ç¹°ã‚Šè¿”ã—å›é¿
                frequency_penalty: 0.1   // è¿½åŠ : èªå½™ã®å¤šæ§˜æ€§å‘ä¸Š
            }),
            signal: AbortSignal.timeout(60000)
        });
        
        console.log("response status:", response.status);
        console.log('=== Step 2: responseç¢ºèª ===');
        
        if (!response.ok) {
            throw new apierror.ChatGPTAPIError(`ChatGPT API Error: ${response.status} ${response.statusText}`);
        }
        
        console.log('=== Step 3: JSON parseé–‹å§‹ ===');
        const data = await response.json();
        
        console.log('=== Step 4: OpenAI APIã®å¿œç­”æ§‹é€ æ¤œè¨¼ ===');
        const validatedData = schema.openAIResponseSchema.parse(data);

        if (validatedData.choices.length === 0) {
            throw new apierror.ChatGPTAPIError('ChatGPT APIã‹ã‚‰ã®å¿œç­”ã«å•é¡ŒãŒã‚ã‚Šã¾ã™');
        }

        console.log('=== Step 5: Questions&ChoicesæŠ½å‡º ===');
        const jsonResponse = validatedData.choices[0].message.content;

        // ä¸è¦ãªæ–‡å­—åˆ—ã®é™¤å»ï¼ˆmarkdownå½¢å¼ç­‰ï¼‰
        let cleanedResponse = jsonResponse.trim();
        cleanedResponse = cleanedResponse.replace(/^```json\s*/, ''); // å…ˆé ­ã®```jsonã‚’å‰Šé™¤
        cleanedResponse = cleanedResponse.replace(/^```.*\n?/, '');   // å…ˆé ­ã®```ã‚’å‰Šé™¤
        cleanedResponse = cleanedResponse.replace(/\n?```$/, '');     // æœ«å°¾ã®```ã‚’å‰Šé™¤
        
        console.log("cleaned JSON response: ", cleanedResponse);

        console.log('=== Step 6: JSON parseå®Ÿè¡Œ ===');
        const result = JSON.parse(cleanedResponse);
        
        //ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã®æ¤œè¨¼
        if (!result.audioScript || !result.answerOptionList) {
            throw new apierror.ChatGPTAPIError('å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆaudioScript, answerOptionListï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™');
        }
        
        // answerOptionãŒé…åˆ—ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
        if(!Array.isArray(result.answerOptionList)) {
            throw new apierror.ChatGPTAPIError('answerOptionListã¯é…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™');
        }
        
        console.log('=== Step 7: æ¤œè¨¼å®Œäº† ===');
        console.log("audioScript length:", result.audioScript.length);
        console.log("answerOptionList:", result.answerOptionList);

        return {
            audioScript: result.audioScript,
            answerOptionList: result.answerOptionList
        };
        
    } catch (error) {
        if (error instanceof SyntaxError) {
            console.error('JSON parse error:', error);
            throw new apierror.ChatGPTAPIError('ChatGPT APIã‹ã‚‰ã®å¿œç­”ãŒæœ‰åŠ¹ãªJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“');
        } else if (error instanceof z.ZodError) {
            console.error(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ:`, error);
            throw new apierror.ChatGPTAPIError(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ: ${error.message}`);
        } else if (error instanceof apierror.ChatGPTAPIError) {
            throw error;
        } else {
            console.error('Unexpected ChatGPT API Error:', error);
            throw new apierror.ChatGPTAPIError('ChatGPT APIã¨ã®é€šä¿¡ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
        }
    }
};

export async function callChatGPTForJpnAudioScript(prompt: string): Promise<string> {
    try {
        console.log('=== Step 1: fetché–‹å§‹ (jpnAudioScriptç”Ÿæˆ) ===');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: "You are an expert Japanese translator specializing in TOEIC materials. Translate the provided English TOEIC content into natural Japanese following the exact format specified in the prompt. Return ONLY the structured Japanese text as specified. Do not include explanations, markdown formatting, JSON, or any additional text."
                    },
                    {
                        role: "user",
                        content: prompt
                    }
                ],
                temperature: 0.3,        //ç¿»è¨³ã®ä¸€è²«æ€§ã‚’ä¿ã¡ã¤ã¤è‡ªç„¶ã•ã‚’ç¢ºä¿
                max_tokens: 2000,       //æ—¥æœ¬èªã¯æ–‡å­—æ•°ãŒå¤šããªã‚‹ãŸã‚å¢—é‡
                top_p: 0.9,
                presence_penalty: 0.1
            }),
            signal: AbortSignal.timeout(90000)
        });
        
        console.log("response status:", response.status);
        console.log('=== Step 2: responseç¢ºèª ===');
        
        if (!response.ok) {
            throw new apierror.ChatGPTAPIError(`ChatGPT API Error: ${response.status} ${response.statusText}`);
        }
        
        console.log('=== Step 3: JSON parseé–‹å§‹ ===');
        const data = await response.json();
        
        console.log('=== Step 4: OpenAI APIã®å¿œç­”æ§‹é€ æ¤œè¨¼ ===');
        const validatedData = schema.openAIResponseSchema.parse(data);

        if (validatedData.choices.length === 0) {
            throw new apierror.ChatGPTAPIError('ChatGPT APIã‹ã‚‰ã®å¿œç­”ã«å•é¡ŒãŒã‚ã‚Šã¾ã™');
        }

        console.log('=== Step 5: jpnAudioScriptæŠ½å‡º ===');
        const jpnAudioScriptContent = validatedData.choices[0].message.content;

        //å‰å¾Œã®ç©ºç™½é™¤å»
        const cleanedJpnAudioScript = jpnAudioScriptContent.trim();
        
        console.log("cleaned jpnAudioScript: ", cleanedJpnAudioScript);
        console.log('=== Step 6: jpnAudioScriptæ¤œè¨¼å®Œäº† ===');
        console.log("generated jpnAudioScript length:", cleanedJpnAudioScript.length);

        return cleanedJpnAudioScript;
        
    } catch (error) {
        if (error instanceof z.ZodError) {
            console.error(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ:`, error);
            throw new apierror.ChatGPTAPIError(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ: ${error.message}`);
        } else if (error instanceof apierror.ChatGPTAPIError) {
            throw error;
        } else {
            console.error('Unexpected ChatGPT API Error:', error);
            throw new apierror.ChatGPTAPIError('ChatGPT APIã¨ã®é€šä¿¡ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
        }
    }
};

export async function callChatGPTForExplanation(prompt: string): Promise<string> {
    try {
        console.log('=== Step 1: fetché–‹å§‹ (explanationç”Ÿæˆ) ===');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
            },
            body: JSON.stringify({
                model: "gpt-4o",
                messages: [
                    {
                        role: "system",
                        content: "You are an expert TOEIC instructor specializing in creating detailed explanations in Japanese. Generate comprehensive explanations that help students understand correct answers, analyze incorrect options, and improve their listening skills. Focus on practical learning points and accent-specific pronunciation guidance. Return ONLY the Japanese explanation text as specified. Do not include formatting, markdown, or additional text."
                    },
                    {
                        role: "user",
                        content: prompt
                    }
                ],
                temperature: 0.4,        // è§£èª¬ã®ä¸€è²«æ€§ã¨æ•™è‚²çš„é…æ…®ã®ãƒãƒ©ãƒ³ã‚¹
                max_tokens: 1500,       // 500-700æ–‡å­—ã®æ—¥æœ¬èªè§£èª¬ã«é©åˆ‡
                top_p: 0.9,
                presence_penalty: 0.1,
                frequency_penalty: 0.1   // èªå½™ã®å¤šæ§˜æ€§ç¢ºä¿
            }),
            signal: AbortSignal.timeout(90000)
        });
        
        console.log("response status:", response.status);
        console.log('=== Step 2: responseç¢ºèª ===');
        
        if (!response.ok) {
            throw new apierror.ChatGPTAPIError(`ChatGPT API Error: ${response.status} ${response.statusText}`);
        }
        
        console.log('=== Step 3: JSON parseé–‹å§‹ ===');
        const data = await response.json();
        
        console.log('=== Step 4: OpenAI APIã®å¿œç­”æ§‹é€ æ¤œè¨¼ ===');
        const validatedData = schema.openAIResponseSchema.parse(data);

        if (validatedData.choices.length === 0) {
            throw new apierror.ChatGPTAPIError('ChatGPT APIã‹ã‚‰ã®å¿œç­”ã«å•é¡ŒãŒã‚ã‚Šã¾ã™');
        }

        console.log('=== Step 5: explanationæŠ½å‡º ===');
        const explanationContent = validatedData.choices[0].message.content;

        //å‰å¾Œã®ç©ºç™½é™¤å»
        const cleanedExplanation = explanationContent.trim();
        
        console.log("cleaned explanation: ", cleanedExplanation);
        console.log('=== Step 6: explanationæ¤œè¨¼å®Œäº† ===');
        console.log("generated explanation length:", cleanedExplanation.length);

        return cleanedExplanation;
        
    } catch (error) {
        if (error instanceof z.ZodError) {
            console.error(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ:`, error);
            throw new apierror.ChatGPTAPIError(`OpenAI APIã‹ã‚‰äºˆæœŸã—ãªã„å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ: ${error.message}`);
        } else if (error instanceof apierror.ChatGPTAPIError) {
            throw error;
        } else {
            console.error('Unexpected ChatGPT API Error:', error);
            throw new apierror.ChatGPTAPIError('ChatGPT APIã¨ã®é€šä¿¡ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ');
        }
    }
};


async function part2AudioScript() {
    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);
    const audioScriptPromptPath = path.join(__dirname, 'test-part2-audioscript-prompt.md');
    const audioScriptPrompt = await fs.readFile(audioScriptPromptPath, 'utf8');
    console.log("testprompt: ", audioScriptPrompt);
    const response = await callChatGPTForPart2AudioScript(audioScriptPrompt);
    console.log("response", response);
};
async function audioScriptContent() {
    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);
    const audioScriptPromptPath = path.join(__dirname, 'test-audioscript-prompt.md');
    const audioScriptPrompt = await fs.readFile(audioScriptPromptPath, 'utf8');
    console.log("testprompt: ", audioScriptPrompt);
    const response = await callChatGPTForAudioScriptContent(audioScriptPrompt);
    console.log("response", response);
};

async function audioScriptQuestions() {
    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);
    const audioScriptPromptPath = path.join(__dirname, 'test-audioscript-questions-prompt.md');
    const audioScriptPrompt = await fs.readFile(audioScriptPromptPath, 'utf8');
    console.log("testprompt: ", audioScriptPrompt);
    const response = await callChatGPTForAudioScriptQuestions(audioScriptPrompt);
    console.log("response", response);
};

async function jpnAudioScript() {
    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);
    const jpnAudioScriptPromptPath = path.join(__dirname, 'test-part2-jpnaudioscript-prompt.md');
    const jpnAudioScriptPrompt = await fs.readFile(jpnAudioScriptPromptPath, 'utf8');
    console.log("testprompt: ", jpnAudioScriptPrompt);
    const response = await callChatGPTForJpnAudioScript(jpnAudioScriptPrompt);
    console.log("response", response);
};

async function explanation() {
    const __filename = fileURLToPath(import.meta.url);
    const __dirname = path.dirname(__filename);
    const explanationPromptPath = path.join(__dirname, 'test-part2-explanation-prompt.md');
    const explanationPrompt = await fs.readFile(explanationPromptPath, 'utf8');
    console.log("testprompt: ", explanationPrompt);
    const response = await callChatGPTForExplanation(explanationPrompt);
    console.log("response", response);
};


//part2AudioScript().catch(console.error);
//audioScriptContent().catch(console.error);
//audioScriptQuestions().catch(console.error);
//jpnAudioScript().catch(console.error);
explanation().catch(console.error);

/*
async function callGoogleCloudTTSRealAPITest() {
    const mockSSML = `<?xml version="1.0" encoding="UTF-8"?>
    <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis">
        <break time="1s"/>

        <!-- Part 4: Talk -->
        <voice name="en-US-Neural2-A">
            <prosody rate="0.9">
                <break time="0.5s"/>
                Good morning everyone. I'm pleased to announce that our company has achieved record sales this quarter. 
                <break time="1s"/>
                Our revenue increased by twenty-five percent compared to last year. 
                <break time="1s"/>
                This success is largely due to our new product line and improved customer service. 
                <break time="1s"/>
                I want to thank all departments for their hard work and dedication. 
                <break time="1s"/>
                Looking ahead, we plan to expand our operations to three new markets next year.
                <break time="1.5s"/>
            </prosody>
        </voice>

        <!-- Questions -->
        <voice name="en-US-Neural2-D">
            <prosody rate="0.9">
                <break time="0.5s"/>
                What is the main topic of the talk? 
                <break time="0.8s"/> 
                A. New employee training 
                <break time="0.8s"/> 
                B. Company financial results 
                <break time="0.8s"/> 
                C. Product development 
                <break time="0.8s"/> 
                D. Market research
                <break time="1.5s"/>
            </prosody>
        </voice>
        <break time="2s"/>
    </speak>`;

    const mockQuestionID = 'listening-part4-ABC12345';

    const result = await apiservice.callGoogleCloudTTS(mockSSML, mockQuestionID);
            
    console.log(`âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ: ãƒãƒƒãƒ•ã‚¡ãƒ‡ãƒ¼ã‚¿: ${result}, éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º ${result.length} bytes`);
    console.log(`âœ… å•é¡ŒID: ${mockQuestionID}`);
};

//éŸ³å£°ç”Ÿæˆé–¢æ•°ã€€controllerã§å‘¼ã³å‡ºã™
export async function generateAudioContent(dto: dto.NewAudioReqDTO, lQuestionID: string): Promise<domein.AudioFilePath> {
    //éŸ³å£°æ€§åˆ¥è¨­å®šå–å¾—
    const genderSettings = GenderRequirementsExtracter.extractGenderRequirements(dto.sectionNumber, dto.audioScript);
    //éŸ³å£°è¨­å®šå–å¾—
    const voiceSettings = TTS_VOICE_CONFIG[dto.speakerAccent as AccentType];
    //ãƒ©ãƒ³ãƒ€ãƒ éŸ³å£°é¸æŠ
    const selectedVoice = TOEICVoiceSelector.selectVoicesForPart(dto.sectionNumber, voiceSettings.voices, genderSettings);
    //audioScriptåˆ†å‰²
    const audioSegmentList = AudioScriptSegmenter.segmentAudioScriptWithGender(dto.audioScript, selectedVoice);
    //SSMLç”Ÿæˆ
    const ssml = await TOEICSSMLGenerator.generateSSML(dto.sectionNumber, audioSegmentList, dto.speakingRate);
    // SSMLæ¤œè¨¼
    validateSSML(ssml);
    //(Google Cloud TTS)éŸ³å£°åˆæˆ
    const audioBufferData = await callGoogleCloudTTS(ssml, lQuestionID);
    //ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã€URLå–å¾—
    const audioFilePath = await saveAudioFile(audioBufferData, lQuestionID);

    return audioFilePath;
};
*/
/*
async function callGoogleCloudTTSRealAPIAndSaveFlieTest() {
    const mockSSML = `<?xml version="1.0" encoding="UTF-8"?>
    <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis">
        <break time="1s"/>

        <!-- Part 4: Talk (British Female Speaker - Company Update) -->
        <voice name="en-GB-Wavenet-A">
            <prosody rate="0.9">
                <break time="0.5s"/>
                Good morning everyone. I'm pleased to announce that our company has achieved record sales this quarter. 
                <break time="1s"/>
                Our revenue increased by twenty-five percent compared to last year. 
                <break time="1s"/>
                This success is largely due to our new product line and improved customer service. 
                <break time="1s"/>
                I want to thank all departments for their hard work and dedication. 
                <break time="1s"/>
                Looking ahead, we plan to expand our operations to three new markets next year. 
                <break time="1s"/>
                We expect this expansion to create approximately fifty new job opportunities across various departments. 
                <break time="1s"/>
                Additionally, we're investing two million dollars in upgrading our technology infrastructure to support future growth.
                <break time="2s"/>
            </prosody>
        </voice>

        <!-- Questions (American Male Speaker) -->
        <voice name="en-US-Wavenet-B">
            <prosody rate="0.9">
                <break time="0.5s"/>
                <!-- Question 1 -->
                What is the main topic of the talk? 
                <break time="0.8s"/> 
                A. New employee training 
                <break time="0.8s"/> 
                B. Company financial results 
                <break time="0.8s"/> 
                C. Product development 
                <break time="0.8s"/> 
                D. Market research
                <break time="2s"/>

                <!-- Question 2 -->
                What contributed to the company's success? 
                <break time="0.8s"/> 
                A. Reduced operating costs 
                <break time="0.8s"/> 
                B. New product line and better customer service 
                <break time="0.8s"/> 
                C. Increased marketing budget 
                <break time="0.8s"/> 
                D. Strategic partnerships
                <break time="2s"/>

                <!-- Question 3 -->
                How many new job opportunities will be created? 
                <break time="0.8s"/> 
                A. Twenty-five 
                <break time="0.8s"/> 
                B. Thirty 
                <break time="0.8s"/> 
                C. Forty 
                <break time="0.8s"/> 
                D. Fifty
                <break time="2s"/>
            </prosody>
        </voice>
        
        <break time="3s"/>
    </speak>`;

    const mockQuestionID = 'listening-part4-ABC12345';

    const response = await apiservice.callGoogleCloudTTS(mockSSML, mockQuestionID);
    console.log(`âœ… éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæˆåŠŸ: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º ${response.length} bytes`);
    const audioFilePath = await apiservice.saveAudioFile(response, mockQuestionID);
    console.log(`âœ… éŸ³å£°ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆæˆåŠŸ`);
};

async function generateAudioContentTest() {
    const mockNewAudioReqDTO: dto.NewAudioReqDTO = {
        sectionNumber: 4,
        audioScript: '[Speaker1_FEMALE] Welcome to City International Airport. [short pause] We are pleased to offer a range of services to enhance your travel experience. [short pause] For your convenience, our information desks are located throughout the terminal, staffed with friendly personnel ready to assist you. [short pause] We also provide complimentary Wi-Fi access, available in all areas of the airport. [short pause] For those traveling with children, our family lounges offer a comfortable space with play areas. [short pause] Additionally, [short pause] we have partnered with local businesses to offer exclusive discounts at various shops and restaurants within the airport. [short pause] Simply present your boarding pass to enjoy these offers. [short pause] We hope you have a pleasant journey. [pause] [Speaker2] [pause] What service is available throughout the airport? [short pause] A. [short pause] Free Wi-Fi access [short pause] B. [short pause] Complimentary meals [short pause] C. [short pause] Personal shopping assistants [short pause] D. [short pause] Free parking [pause] What should passengers show to get discounts? [short pause] A. [short pause] Passport [short pause] B. [short pause] Boarding pass [short pause] C. [short pause] Flight ticket [short pause] D. [short pause] ID card [pause] Where can families find a comfortable space? [short pause] A. [short pause] Information desks [short pause] B. [short pause] Family lounges [short pause] C. [short pause] Business lounges [short pause] D. [short pause] Security area',
        speakerAccent: "American",
        speakingRate: 1.0
    };
    const mockQuestionID = 'listening-part4-ABC12345';
    const audioFilePath = await apiservice.generateAudioContent(mockNewAudioReqDTO, mockQuestionID);
    console.log(`âœ… éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€£çµãƒ†ã‚¹ãƒˆæˆåŠŸ: ${audioFilePath}`);
};
*/

export function createDummyRequest(): Partial<Request> {
    return {
        session: {
            id: 'test-session-12345',
            questionSet: {
                sectionNumber: 2,
                totalQuestionNum: 5,
                currentIndex: 0,
                speakerAccentList: ['American', 'British', 'Canadian', 'Australian', 'American'],
                settingList: [
                    { location: 'airport', speaker: 'traveler', situation: 'facility inquiry' },
                    { location: 'office', speaker: 'employee', situation: 'work progress' },
                    { location: 'restaurant', speaker: 'customer', situation: 'order taking' },
                    { location: 'hotel', speaker: 'guest', situation: 'check-in' },
                    { location: 'store', speaker: 'shopper', situation: 'product inquiry' }
                ],
                speakingRate: 1.0
            },
            // æœ€å°é™ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
            save: (callback?: (err: any) => void) => {
                if (callback) callback(null);
            },
            destroy: (callback?: (err: any) => void) => {
                if (callback) callback(null);
            }
        } as any,
        body: {},
        headers: {},
        method: 'POST',
        url: '/api/question/part2/generate'
    };
}

interface TestResponse {
    res: Partial<Response>;
    responseData: any;
    statusCode: number;
}

export function createDummyResponse(): TestResponse {
    let responseData: any = null;
    let statusCode: number = 200;
    
    const res: Partial<Response> = {
        json: (data: any) => {
            responseData = data;
            console.log('ğŸ“¤ ãƒ¬ã‚¹ãƒãƒ³ã‚¹:', data);
            return res as Response;
        },
        status: (code: number) => {
            statusCode = code;
            console.log(`ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: ${code}`);
            return {
                json: (data: any) => {
                    responseData = data;
                    console.log(`âŒ ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ [${code}]:`, data);
                    return res as Response;
                }
            } as any;
        }
    };
    return { 
        res, 
        get responseData() { return responseData; }, 
        get statusCode() { return statusCode; } 
    };
}

async function testPart2Integration() {
    console.log('ğŸš€ Part2çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹');
    console.log('=====================================');
    
    // Arrange
    const req = createDummyRequest() as Request;
    const { res, responseData, statusCode } = createDummyResponse();
    
    // ãƒ†ã‚¹ãƒˆé–‹å§‹æ™‚åˆ»
    const startTime = Date.now();
    console.log(`â° é–‹å§‹æ™‚åˆ»: ${new Date().toISOString()}`);
    
    try {
        // Act - å®Ÿéš›ã®Controllerå®Ÿè¡Œ
        console.log('ğŸ“‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±:');
        console.log('  - sectionNumber:', req.session.questionSet?.sectionNumber);
        console.log('  - currentIndex:', req.session.questionSet?.currentIndex);
        console.log('  - totalQuestionNum:', req.session.questionSet?.totalQuestionNum);
        console.log('  - speakingRate:', req.session.questionSet?.speakingRate);
        
        await controller.generatePart2LQuizController(req, res as Response);
        
        // Assert - çµæœæ¤œè¨¼
        const endTime = Date.now();
        const executionTime = endTime - startTime;
        
        console.log('=====================================');
        console.log('âœ… ãƒ†ã‚¹ãƒˆå®Œäº†');
        console.log(`â±ï¸  ç·å‡¦ç†æ™‚é–“: ${executionTime}ms (${(executionTime/1000).toFixed(2)}ç§’)`);
        
        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ¤œè¨¼
        if (responseData) {
            console.log('ğŸ“Š çµæœæ¤œè¨¼:');
            console.log(`  - questionHash: ${responseData} (${typeof responseData})`);
            console.log(`  - hashé•·ã•: ${responseData.length}æ–‡å­—`);
            
            if (typeof responseData === 'string' && responseData.length === 12) {
                console.log('âœ… questionHashå½¢å¼: OK');
            } else {
                console.log('âŒ questionHashå½¢å¼: NG');
            }
        }
        
        // DBç¢ºèªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        console.log('ğŸ“‹ æ¬¡ã®ç¢ºèªé …ç›®:');
        console.log('  - DBã«å•é¡Œãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹');
        console.log('  - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹');
        console.log('  - ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®currentIndexã¯æ›´æ–°ã•ã‚ŒãŸã‹');
        
    } catch (error) {
        const endTime = Date.now();
        console.log('=====================================');
        console.log('âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—');
        console.log(`â±ï¸  å®Ÿè¡Œæ™‚é–“: ${endTime - startTime}ms`);
        console.error('ğŸ’¥ ã‚¨ãƒ©ãƒ¼è©³ç´°:', error);
        
        if (error instanceof Error) {
            console.error('ğŸ“ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:', error.message);
            console.error('ğŸ“š ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:', error.stack);
        }
    }
}

// ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
testPart2Integration();
